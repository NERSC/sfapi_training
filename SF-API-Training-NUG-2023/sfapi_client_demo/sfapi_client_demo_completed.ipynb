{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# sfapi_client Demo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sfapi_client import Client\n",
    "from sfapi_client.compute import Machine\n",
    "\n",
    "from pathlib import Path\n",
    "from authlib.jose import JsonWebKey\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "## Setup keys and get user and project information\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I've stored my key is stored in a file in `~/.superfacility/`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls -la ~/.superfacility/*.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paste the client_id for the key here\n",
    "client_id = \"\"\n",
    "\n",
    "# Get the path for your json file here\n",
    "sfapi_key = Path().home() / \".superfacility\" / \"sfapi_training.json\"\n",
    "\n",
    "# This opens the json file and reads it into a format the client understands\n",
    "with sfapi_key.open('r') as sfapi_json:\n",
    "    client_secret = JsonWebKey.import_key(json.loads(sfapi_json.read()))\n",
    "    \n",
    "# We'll use `client_id` and `client_secret` through the rest of our tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Lets make sure we're authenticated and check who the api thinks we are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a client\n",
    "client = Client(client_id, client_secret)\n",
    "\n",
    "# Get the user info, \"Who does the api think I am?\"\n",
    "user = client.user()\n",
    "\n",
    "# Close the connection to the client\n",
    "client.close()\n",
    "\n",
    "# Let's see what the user object has in it\n",
    "user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All data from the object can be retrived from the property name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Or serialized into a dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user.dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we start let's make some useful variables for our home and scratch directory\n",
    "\n",
    "#### Your home and scratch paths are based on your username \n",
    "\n",
    "\n",
    "* `/global/homes/username_first_letter/username`\n",
    "* `/pscratch/sd/username_first_letter/username`\n",
    "\n",
    "\n",
    "#### Let's make two variables to hold our scratch and home paths for later.\n",
    "\n",
    "* __Bonus points for using the `user` object to automatically generate it__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "home_path = f\"/global/homes/{user.name[0]}/{user.name}\"\n",
    "scratch_path = f\"/pscratch/sd/{user.name[0]}/{user.name}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself!\n",
    "\n",
    "1) Using the user object list the `projects` you are a part of.\n",
    "\n",
    "2) From our list of projects print the hours given to the project.\n",
    "\n",
    "3) From our list of projects print the hours left in the project.\n",
    "\n",
    "4) From our list of projects print the disk usage of differnt groups in the project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    user = client.user()\n",
    "    projects = user.projects()\n",
    "    # Projects will be a list of the project objects\n",
    "projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each project\n",
    "# Print the information you want\n",
    "for project in projects:\n",
    "    print(\"=\"*50)\n",
    "    print(f\"{project.repo_name: <15}| {project.project_hours_given:0.2f} Hours | {project.project_hours_given-project.project_hours_used:0.2f} Hours\")\n",
    "    print(\"-\"*50)\n",
    "    for projdir_usage in project.projdir_usage:\n",
    "        print(f\"{projdir_usage.name: <15}| {projdir_usage.bytes_used_human}\")\n",
    "    \n",
    "# It may be helpful to view what jupter displays for one project in the list\n",
    "# Uncomment and run to see that the project object has in it\n",
    "# projects[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Exercise 2\n",
    "## Check Perlmutter status and queues\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Before we start any computing, let's check that Perlmutter is up.\n",
    "\n",
    "Our compute object has information about the status of the machine.\n",
    "It is also used to get the queue information and run commands and jobs on the system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    \n",
    "perlmutter.status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also check the status of other systems under the `resources` section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    nersc_status = client.resources.status()\n",
    "\n",
    "# For each of the resources print the status\n",
    "for name, status in nersc_status.items():\n",
    "    print(f\"{name: <20}| {status.description: <25}| {status.status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself\n",
    "\n",
    "1) Use resources to any `outages` for Perlmutter.\n",
    "\n",
    "2) Use the compute object to get the jobs in the partition `gpu_ss11`.\n",
    "\n",
    "3) Which job is requesting the highest number of nodes right now?\n",
    "\n",
    "    - If you're familiar with pandas: `pd.DataFrame([j.dict() for j in all_jobs])`\n",
    "    \n",
    "4) Use the compute object to get past jobs for a user."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Similar to getting the resourse status but now let's try outages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    # Similiar to before but this time let's get the outages\n",
    "    nersc_status = client.resources.outages()\n",
    "    \n",
    "# The `nersc_status` object is a dictionary of lists of outages\n",
    "# Get the list you want from the dictionary based on the name\n",
    "nersc_status['perlmutter'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find out the next time there's an scheduled outage\n",
    "for name, status in nersc_status.items():\n",
    "    print(f\"{name.ljust(20)}| {str(status[0].start_at).ljust(25)}| {status[0].status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's look at the `jobs` on Perlmutter\n",
    "\n",
    "We can search just the gpu queue based on the slurm `partition` `'gpu_ss11'`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    # Get all GPU jobs\n",
    "    all_jobs = perlmutter.jobs(partition='gpu_ss11')\n",
    "# Let's just print a few\n",
    "all_jobs[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through all the jobs and find the job with the highest number of nodes\n",
    "max_nodes_job_id = None\n",
    "max_nodes = 0\n",
    "for job in all_jobs:\n",
    "    if job.state != \"RUNNING\":\n",
    "        continue\n",
    "    # job.nodes is a string, remember to convert it to an int for the max comparison\n",
    "    num_nodes = int(job.nodes)\n",
    "    if num_nodes > max_nodes:\n",
    "        max_nodes = num_nodes\n",
    "        max_nodes_job_id = job.jobid\n",
    "\n",
    "print(max_nodes_job_id, max_nodes)\n",
    "# For a bonus get the max_nodes_job_id and max_nodes for a job which `state` is \"RUNNING\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jobs can also be easily loaded into pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# Get the jobs into a dataframe\n",
    "df = pd.DataFrame([j.dict() for j in all_jobs])\n",
    "# Convert the column to ints\n",
    "df['nodes'] = df.nodes.astype(int)\n",
    "# Select jobs that are running\n",
    "df_running = df[df.state == \"RUNNING\"]\n",
    "# Get the largest based on the id of the max and the location \n",
    "df_running.loc[df_running.nodes.idxmax()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can also get previous jobs based on the jobid or the user who ran it\n",
    "\n",
    "Let's see if you've run any jobs in the last ~24 hours (that's the default time frame `sacct` returns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    past_jobs = perlmutter.jobs(user=user.name)\n",
    "\n",
    "for job in past_jobs:\n",
    "    print(job.jobid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# \n",
    "# Exercise 3\n",
    "## Submit a job\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now let's run a job\n",
    "\n",
    "The job script below will run a simple python program to generate random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 1000\n",
    "\n",
    "job_script = f\"\"\"#!/bin/bash\n",
    "\n",
    "#SBATCH -q debug\n",
    "#SBATCH -A ntrain3\n",
    "#SBATCH -N 1\n",
    "#SBATCH -C cpu\n",
    "#SBATCH -t 00:10:00\n",
    "#SBATCH -J sfapi-demo\n",
    "#SBATCH --exclusive\n",
    "#SBATCH --output={scratch_path}/sfapi-demo/sfapi-demo-%j.out\n",
    "#SBATCH --error={scratch_path}/sfapi-demo/sfapi-demo-%j.error\n",
    "\n",
    "module load python\n",
    "# Prints N random numbers to form a normal disrobution\n",
    "python -c \"import numpy as np; numbers = np.random.normal(size={N}); [print(n) for n in numbers]\"\n",
    "\"\"\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make sure your `scratch_path` is set properly in the job script and that it looks good to submit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(job_script)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make sure our output folder is there for our data to go to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    # This will run a command on perlmutter, here we use `mkdir` to make our output directory\n",
    "    perlmutter.run(f\"mkdir -p {scratch_path}/sfapi-demo\")\n",
    "    # We can run ls on the directory to see that it was created\n",
    "    [output_dir] = perlmutter.ls(f\"{scratch_path}/sfapi-demo\", directory=True)\n",
    "\n",
    "# Check that the directory is there\n",
    "output_dir.is_dir()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try it yourself\n",
    "\n",
    "1) Using our compute object submit a job to Perlmutter using the `job_script` and wait for it to complete.\n",
    "\n",
    "2) Find out what node the job ran on.\n",
    "\n",
    "2) Using our compute object `ls` to find the outputfile.\n",
    "\n",
    "3) Download the output file and read it's contents.\n",
    "\n",
    "4) Plot the results!\n",
    "\n",
    "    - The output file has one number (as a string) per newline `\\n`\n",
    "    - Split the file by newline\n",
    "    - Convert the numbers to floats, get rid of anything that's not a number\n",
    "    - Plot the numbers in a histogram to see the distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the job and wait for the job to complete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    job = perlmutter.submit_job(job_script)\n",
    "    # Let's save the job id to use later \n",
    "    job_id = job.jobid\n",
    "\n",
    "    print(f\"Waiting for job {job_id} to finish!\")\n",
    "    # Wait for the job to finish\n",
    "    job.complete()\n",
    "    print(\"Done!\")\n",
    "    \n",
    "    \n",
    "job.state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### You can also get the same information about the job based on it's jobid\n",
    "\n",
    "Use the `job_id` we saved before to print which node the job ran on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    job = perlmutter.job(jobid=job_id)\n",
    "\n",
    "job.nodelist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from the slurm output file\n",
    "\n",
    "Our output file will name is based on the job id, \"sfapi-demo-__jobid__.out\" in the scratch directory we created before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with Client(client_id, client_secret) as client:\n",
    "    perlmutter = client.compute(Machine.perlmutter)\n",
    "    [output_file] = perlmutter.ls(f\"{scratch_path}/sfapi-demo/sfapi-demo-{job.jobid}.out\")\n",
    "    print(f\"Is the file there? {output_file.is_file()}\")\n",
    "    \n",
    "    output_file_numbers = output_file.download()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the output file and convert the strings to `float` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_numbers = output_file_numbers.read()\n",
    "numers = list(map(float, output_numbers.split(\"\\n\")[:-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(numers, bins=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook by Nick Tyler\n",
    "\n",
    "### Acknowledgements\n",
    "\n",
    "- Bjoern Enders (Co-Leading the API Training)\n",
    "- Chris Harris (Co-Author sfapi_client)\n",
    "- Gabor Torok (Author api.nersc.gov)\n",
    "- Charles Lively (Helping during training event)\n",
    "- Seleste Rodriguez, Lipi Gupta (Helping with training accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
